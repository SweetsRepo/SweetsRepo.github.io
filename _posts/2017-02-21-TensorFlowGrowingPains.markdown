---
layout: post
title: TensorFlow: Growing Pains
date: 2017-02-21T17:16:00.000Z
categories: update
---
<img src="/images/fulls/02.png" class="fit image">

The past week has been a perfect example of simple tasks gone wrong. It was as
simple as this; define and train a model in TensorFlow, then save it so that 
predictions may be made outside of the module. Sounds straightforward, right?
Well, you'd be wrong. Horifically so as a matter of fact.

Let's start with the inspiration for this little adventure. I'm currently 
working on a system which will first learn to classify handwritten numbers and 
subsequently begin generating it's own examples. As new samples are
generated by the second part of the model they are classified by the 
discriminator from the first part of the model. This bi-model system is known 
as a Generative Adversarial Network, developed by Ian Goodfellow in 2014. For 
more information on it feel free to check out this paper: https://arxiv.org/pdf/1406.2661.pdf

The largest issue with this system is that it takes a long time to train. 
Each model (referred to as the discriminator and generator herein) uses a 
CNN featuring 2 convolution and pooling layers, followed by 2 affine layers. 
Training for the discriminator alone takes close to an hour. The generator 
will take even longer. To put it into perspective I started training the model
as I began this post and is still running after writing, proofreading, and 
restructuring. 

So of course one would logically say let's save the trained model
once we know it works and never train it again. Just spawn an instance of the
tf.train.Saver() object and call it's save() method. Nope. 

Maybe if I play with the __init__() parameters like max_to_keep and keep a few 
backups as I train. Nope. 

Surely the TensorFlow Docs will be able to help. Nope, turns out Google
is in the process of releaseing TFr1.0 and half their old documentation pages
are returning a 404. 

I know, I'll go to stack overflow! Wait... this post says to save .ckpt files,
and this one says to save .meta files. Huh, I tried both and haven't had any 
luck. 

What about adding variables to a collection using 
tf.add_to_collection('vars', my_var). This one I won't completely discredit, 
as I believe it's failure is due to my sloppy coding, not the API. By the way
always give your variables an explicit name when you define them in TensorFlow.
I failed to do this and think the above solution would have worked had I not 
been lazy. In case you don't understand what I mean by this, here's an example
var_n = tf.Variable(blah, name='n'), where n is your desired name.

So why is it so hard to save models trained using TensorFlow? Well it has to 
do with the architecture of the API itself. Everything in TensorFlow remains 
undefined/as a placeholder until evaluted within a TensorFlow Session. This makes
extracting values pretty easy, as we just train and evaluate the model. But 
restoring them is far more challenging, as a session must have been started to
place the variables into when loading from the .meta file. This is where I
believe naming of variables to be critical. The functionality just doesn't seem
to completely be there yet.

I can keep on going, but at this point I've lost a week to what I would have 
expected to be a trivial task. So instead I'm banking on my system being 
correct and will let the code run overnight. The moral is, don't underestimate
any task, no matter how trivial it may seem. Hopefully in later releases of TF
it will be easier to save trained meta-graphs.
